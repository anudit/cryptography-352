{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "crypto-proj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d_NAWnAACFC"
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFvoC2zu9y9i"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import syft as sy \n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "GJQmycGz9y9c"
      },
      "source": [
        "epochs = 10\n",
        "n_train_items = 60000\n",
        "n_test_items = 10000"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uciOQdo9y9l"
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 128\n",
        "        self.test_batch_size = 128\n",
        "        self.epochs = epochs\n",
        "        self.lr = 0.01\n",
        "        self.seed = 1\n",
        "        self.log_interval = 1\n",
        "        self.precision_fractional = 3\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "_ = torch.manual_seed(args.seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LITzMK6O9y9o"
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "def connect_to_workers(n_workers):\n",
        "    return [\n",
        "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
        "        for i in range(n_workers)\n",
        "    ]\n",
        "def connect_to_crypto_provider():\n",
        "    return sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
        "\n",
        "workers = connect_to_workers(n_workers=2)\n",
        "crypto_provider = connect_to_crypto_provider()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r8gIt0U9y9r"
      },
      "source": [
        "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
        "    \n",
        "    def one_hot_of(index_tensor):\n",
        "        onehot_tensor = torch.zeros(*index_tensor.shape, 10)\n",
        "        onehot_tensor = onehot_tensor.scatter(1, index_tensor.view(-1, 1), 1)\n",
        "        return onehot_tensor\n",
        "        \n",
        "    def secret_share(tensor):\n",
        "        return (\n",
        "            tensor\n",
        "            .fix_precision(precision_fractional=precision_fractional)\n",
        "            .share(*workers, crypto_provider=crypto_provider, protocol=\"fss\", requires_grad=True)\n",
        "        )\n",
        "    \n",
        "    transformation = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True, transform=transformation),\n",
        "        batch_size=args.batch_size\n",
        "    )\n",
        "    \n",
        "    private_train_loader = [\n",
        "        (secret_share(data), secret_share(one_hot_of(target)))\n",
        "        for i, (data, target) in enumerate(train_loader)\n",
        "        if i < n_train_items / args.batch_size\n",
        "    ]\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, download=True, transform=transformation),\n",
        "        batch_size=args.test_batch_size\n",
        "    )\n",
        "    \n",
        "    private_test_loader = [\n",
        "        (secret_share(data), secret_share(target.float()))\n",
        "        for i, (data, target) in enumerate(test_loader)\n",
        "        if i < n_test_items / args.test_batch_size\n",
        "    ]\n",
        "    \n",
        "    return private_train_loader, private_test_loader\n",
        "    \n",
        "    \n",
        "private_train_loader, private_test_loader = get_private_data_loaders(\n",
        "    precision_fractional=args.precision_fractional,\n",
        "    workers=workers,\n",
        "    crypto_provider=crypto_provider\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ihEbwIJ9y9u"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2lKhfoQ9y9x"
      },
      "source": [
        "def train(args, model, private_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(private_train_loader):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        batch_size = output.shape[0]\n",
        "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
        "        loss.backward()        \n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get().float_precision()\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.3f}s'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(private_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(private_train_loader), loss.item(), time.time() - start_time))\n",
        "            "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTfYcY3p9y9z"
      },
      "source": [
        "def test(args, model, private_test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in private_test_loader:\n",
        "            start_time = time.time()\n",
        "            \n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target.view_as(pred)).sum()\n",
        "\n",
        "    correct = correct.get().float_precision()\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct.item(), len(private_test_loader)* args.test_batch_size,\n",
        "        100. * correct.item() / (len(private_test_loader) * args.test_batch_size)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hdTt8Ox9y92",
        "outputId": "9bfb3959-85ea-4057-d37b-a0cc1b93cd38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Net()\n",
        "model = model.fix_precision().share(*workers, crypto_provider=crypto_provider, protocol=\"fss\", requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "optimizer = optimizer.fix_precision() \n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, private_train_loader, optimizer, epoch)\n",
        "    test(args, model, private_test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py:122: UserWarning: Use dtype instead of field\n",
            "  warnings.warn(\"Use dtype instead of field\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 1.120000\tTime: 8.112s\n",
            "Train Epoch: 1 [128/60032 (0%)]\tLoss: 1.076000\tTime: 8.131s\n",
            "Train Epoch: 1 [256/60032 (0%)]\tLoss: 1.048000\tTime: 8.134s\n",
            "Train Epoch: 1 [384/60032 (1%)]\tLoss: 1.007000\tTime: 8.167s\n",
            "Train Epoch: 1 [512/60032 (1%)]\tLoss: 1.013000\tTime: 8.120s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}